{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Predicting Educational Disadvantage from Czech School Inspectorate Reports: A Textual Data Analysis Approach",
   "id": "673334c05798d83d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T17:58:55.880475Z",
     "start_time": "2024-08-16T17:58:55.876184Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Display the saved plots (as plot do not show when separate code is called from the notebook\n",
    "from IPython.display import Image, display\n",
    "\n",
    "import os\n"
   ],
   "id": "b45e0b3a17017f21",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Introduction\n",
    "### 2.1. Research Question:\n",
    "Can textual data from Czech School Inspectorate (ČŠI) reports be used to predict educational disadvantage or failure in schools?\n",
    "\n",
    "### 2.2. Motivation:\n",
    "\n",
    "1. Education policy impact <br>\n",
    "Education in Czechia suffers from a big differences in educational quality in primary education. Simply put, not all shools perform the same and student's educational outcome depends quite heavily on their place of birth. Differences in education exist between regions and also between schools within a region. Identifying schools at risk can help inform necessary interventions and allocation of resources. <br>\n",
    "SOURCES: **XXXX**<br>\n",
    "<br>\n",
    "2. Use of text data in education <br>\n",
    "Traditionally, educational outcomes are analyzed using quantitative data like test scores or graduation rates. Textual data are not yet used for country-wide predictions of disadvantaged schools. They are frankly not used much for any country-wide evaluation. Textual data is also unstructured and rich in information. Analyzing this data could reveal patterns and indicators of disadvantage that are overlooked in structured data."
   ],
   "id": "55d1d0cf43ac5fb1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. Methods\n",
    "The analysis employs a combination of text understanding and processing methods in combination with advanced machine learning techniques (Lasso regression and mainly a deep neural network model). The main model is trained on a dataset of school disadvantage probabilities.\n",
    "\n",
    "### 3.1 Data sources\n",
    "1. ***Inspection reports*** from Czech School Inspectorate (pdf files from an inspectorate website)<br>\n",
    "Basic school metadata and detailed evaluations of school performance, including descriptions of teaching quality, school management, student outcomes, and other relevant factors.\n",
    "2. ***School disadvantage data***<br>\n",
    "Currently not publicly available. The data were calculated and shared from a former employee of the Czech Ministry of Education Jiri Munich.\n",
    "\n",
    "### 3.2 Text processing\n",
    "The textual data go though a several preprocessing steps to transform the raw text into a structured and analyzable format.\n",
    "\n",
    "1. **Tokenization and Lemmatization**\n",
    "   - The raw text of the reports is broken down into individual tokens, mostly single words. Tokenization helps in handling the text at a granular level, making it easier to perform subsequent text processing tasks. Lemmatization is applied to reduce words to their base or root forms. For example, \"running\" becomes \"run\". This step is crucial for handling the complexities of the Czech language, where words can have multiple inflected forms.\n",
    "   - **Tool Used**: The task is performed with the `Morphodita` library. A library developed for processing Czech language data.\n",
    "2. **Stop Words and Noise Removal**:\n",
    "   - Common stop words (e.g., \"and\", \"the\") and non-informative tokens are removed to focus on the most meaningful content.\n",
    "3. **TF-IDF (Term Frequency-Inverse Document Frequency)**:\n",
    "   - TF-IDF is used to convert the cleaned text data into numerical features. It reflects how important a word is to a document in the corpus.\n",
    "   - The `TfidfVectorizer` from `scikit-learn` is used to calculate the TF-IDF values for the tokens in each report.\n",
    "4**Principal Component Analysis (PCA)**:\n",
    "   - PCA is applied to the TF-IDF features to reduce the dimensionality of the data while preserving as much variance as possible. The resulting principal components are used as input features for further analysis, reducing computational complexity and enhancing model performance.\n",
    "   - The `PCA` module from `scikit-learn` is used to transform the high-dimensional TF-IDF matrix into a smaller set of uncorrelated features (principal components).\n",
    "\n",
    "### 3.3 Analysis methods\n",
    "\n",
    "#### Correlation Analysis\n",
    "- **Initial Exploration**: A correlation analysis is performed to understand the relationships between the principal components (PCs) derived from the text data and the target variable, which represents educational disadvantage.\n",
    "\n",
    "#### Lasso Regression\n",
    "- **Initial Modeling**: Before implementing the neural network, a Lasso regression is applied to the dataset for future comparison and better understanding of the role of the components.\n",
    "\n",
    "#### Neural Network Model\n",
    "- **Architecture**: The core of the analysis relies on a neural network with three hidden layers, chosen from a collection of other settings by eyeballing the outcomes and by other evaluation metrics. This architecture allows the model to learn intricate, non-linear relationships in the data. The use of multiple layers is crucial for capturing the hierarchical nature of the data, where lower layers learn basic patterns, and higher layers build on these to recognize more complex structures.\n",
    "- **Sigmoid Output**: A sigmoid activation function is chosen for the output layer to ensure that the predictions are bounded between 0 and 1, aligning with the nature of the target variable (a measure of disadvantage).\n",
    "\n",
    "#### Model Evaluation\n",
    "- **Predictive Power**: The effectiveness of the model is assessed by its ability to accurately predict the target variable on the test set. This involves comparing the predicted values against the actual values to determine how well the model generalizes to unseen data.\n",
    "- **Mean Squared Error (MSE)**: The model's performance is evaluated using Mean Squared Error, which measures the average squared difference between the predicted and actual values. A lower MSE indicates better predictive accuracy and fewer large errors.\n",
    "- **R-squared (R²)**: R-squared is another metric used to evaluate the model, representing the proportion of the variance in the dependent variable that is predictable from the independent variables. A higher R-squared value indicates that the model explains a significant portion of the variability in the outcome variable.\n",
    "\n",
    "\n",
    "### Causality Considerations\n",
    "- **Correlation vs. Causation**: While the neural network model identifies patterns and makes predictions, it is fundamentally based on correlations in the data. This means that while the model can suggest which factors are associated with educational disadvantage, it cannot establish causal relationships. For instance, if a certain word or phrase frequently appears in reports for disadvantaged schools, the model might predict disadvantage based on this feature, but this does not imply that the word or phrase causes the disadvantage.\n",
    "- **Assumptions**: The analysis assumes that the patterns in the textual data are consistent and that the principal components effectively capture the most relevant information. Additionally, the neural network's predictive power relies on the assumption that the training data is representative of the broader population of school reports.\n",
    "\n",
    "In summary, the methods used in this analysis are ***primarily correlational***. The neural network model is a powerful tool for prediction, but offers in this state of the project ***no causal interpretations***."
   ],
   "id": "b2e51133029888aa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. Results\n",
    "\n",
    "### Neural network\n",
    "- ***MSE***: When faced with smaller dataset of schools which have a) relatively high confidence of either advantage or disadvantage and b) available inspection reports to match, the final MSE is **0.02375**, this suggests that the model is generally accurate in its predictions. Initially, there is a sharp decline in the MSE, indicating that the model quickly learns from the data. However, after around 20 epochs, the validation loss stabilizes, suggesting that further training does not significantly improve the model's performance. The divergence between the training and validation losses suggests a later seen smaller effectively on unseen data.\n",
    "\n",
    "![Learning Curves](plots/Learning Curves.png)\n",
    "\n",
    "- ***True vs Predicted Values***: The scatter plot shows that the model is reasonably good at predicting school with low chance of being disadvantaged (<0.5), but does not really predict well schools with high known probability of disadvantage.\n",
    "\n",
    "![True vs Predicted Values](plots/True vs Predicted Values.png)\n",
    "\n",
    "- ***Residual Analysis***: The histogram of residuals shows a roughly normal distribution centered around zero. This is a good sign, as it suggests that the model's errors are randomly distributed rather than systematically biased. However, the presence of outliers and the spread of residuals suggest that there are instances where the model's predictions are significantly off.\n",
    "\n",
    "![Histogram of Residuals](plots/Histogram of Residuals.png)"
   ],
   "id": "b813d24c40b40251"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5. Step by step explanation of the code\n",
    "As the code is quite extensive, the individual sections are in their own individual scripts, which can be started from here. Detailed explanation of the code is in each individual script."
   ],
   "id": "5e51490e7ae566ec"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 5.1 Downloading the inspectorate reports\n",
    "The following code uses a csv called 'inspekcni_zpravy.csv', downloaded from the czech inspectorate. This dataset has basic school metadata and website links to inspection reports.\n",
    "AS the dataset is quite large, the code is currently limited to report_limit = 100, after which it stops downloading. If you want to download all reports, increase the limit. The total data entries is more than 14 000. "
   ],
   "id": "af6b3423b05da56a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T17:59:10.705222Z",
     "start_time": "2024-08-16T17:59:07.970564Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#set where your scripts are located\n",
    "os.chdir('C:/++4630/++ University, education/03 -- Tilburg_v02/Data Science/scripts')\n",
    "\n",
    "!python download_inspection.py"
   ],
   "id": "86fa1d7a45d6fdcf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text file already exists for REDIZO 600117782. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 665101872. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 691002029. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600126625. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600099121. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600036499. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 691000336. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600025900. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 691004153. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600148858. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600098800. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600079597. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600008487. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600138623. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600061515. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 691004943. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 651039983. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600110117. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 691004323. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600076211. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600105211. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 691004650. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600100758. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600043096. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600086976. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 650063325. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 691005206. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 650045424. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600149935. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 650065115. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 651037565. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 650031679. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 650052960. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600146286. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600059596. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 691005575. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600102106. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600023087. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600044092. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600037606. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600106276. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 610451251. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 667000194. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600076881. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600045595. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600050271. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600148998. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600111741. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600006760. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600019896. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600096319. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600117910. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 650060997. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 650056451. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600114287. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600165973. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600009289. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600107957. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600126978. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600003175. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600069532. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600083870. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600027457. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 691004579. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600121712. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600002900. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600043169. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600116964. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 650064917. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600123561. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 650013638. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600130827. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600117332. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600027180. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600048942. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600149714. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600011488. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600109640. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600072002. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600027384. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600050475. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600099318. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600005682. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600036740. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600044173. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600123537. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600104877. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600044394. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600061647. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600090302. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 650033841. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600091660. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600012891. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600041620. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600044882. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 691000549. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600097633. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 650025610. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 691005931. Skipping download and extraction.\n",
      "Text file already exists for REDIZO 600013464. Skipping download and extraction.\n",
      "Processing complete. 100 reports processed.\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 5.2 Preprocessing the text\n",
    "The following code processes text reports from a directory of inspection reports. It uses the Morphodita library for lemmatization and part-of-speech (POS) tagging. \n",
    "\n",
    "1. **Report Processing Limit**: The script is set to process up to `20,000` reports, but this can be adjusted with the `report_limit` variable.\n",
    "\n",
    "2. **Directory Paths**: \n",
    "   - The original text files are located in the `../data/csi_reports/` directory.\n",
    "   - Processed text files are saved in the `../data/processed/` directory, which is created if it doesn't already exist.\n",
    "\n",
    "3. **Morphodita Initialization**: \n",
    "   - The Morphodita model is loaded from `../models/czech-morfflex2.0-pdtc1.0-220710/czech-morfflex2.0-pdtc1.0-220710-no_dia.tagger`.\n",
    "   - The tokenizer is initialized to break down the text for processing.\n",
    "  - [Visit the Morphodita website for detailed information on the package](https://ufal.mff.cuni.cz/morphodita)\n",
    "\n",
    "\n",
    "4. **Text Preprocessing**: \n",
    "   - For each text file in the directory:\n",
    "     - If the file has already been processed, it is skipped.\n",
    "     - The text is read and tokenized.\n",
    "     - Lemmatization and POS tagging are performed, retaining only nouns, adjectives, and verbs.\n",
    "     - The processed text is saved with the same filename in the `processed` directory."
   ],
   "id": "8310e13dbcebeeb3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T18:03:13.888891Z",
     "start_time": "2024-08-16T18:03:08.295433Z"
    }
   },
   "cell_type": "code",
   "source": "!python preprocess_texts.py",
   "id": "f24e16b692f94b7d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 600000206_2021_MateĹ™skĂˇ Ĺˇkola sv. VorĹˇily v Praze_inspection_report.txt already processed. Skipping...\n",
      "File 600000222_2017_CĂ­rkevnĂ­ mateĹ™skĂˇ Ĺˇkola StudĂˇnka_inspection_report.txt already processed. Skipping...\n",
      "File 600000222_2024_CĂ­rkevnĂ­ mateĹ™skĂˇ Ĺˇkola StudĂˇnka_inspection_report.txt already processed. Skipping...\n",
      "File 600000231_2018_ModrĂ˝ klĂ­ÄŤ - zĂˇkladnĂ­ Ĺˇkola speciĂˇlnĂ­ a mateĹ™skĂˇ Ĺˇkola speciĂˇlnĂ­, o.p.s._inspection_report.txt already processed. Skipping...\n",
      "File 600000249_2019_CĂ­rkevnĂ­ mateĹ™skĂˇ Ĺˇkola SrdĂ­ÄŤko_inspection_report.txt already processed. Skipping...\n",
      "File 600000257_2016_BilingvĂˇlnĂ­ mateĹ™skĂˇ Ĺˇkola pro sluchovÄ› postiĹľenĂ© s.r.o._inspection_report.txt already processed. Skipping...\n",
      "File 600000257_2023_BilingvĂˇlnĂ­ mateĹ™skĂˇ Ĺˇkola pro sluchovÄ› postiĹľenĂ© s.r.o._inspection_report.txt already processed. Skipping...\n",
      "File 600000265_2017_SOUKROMĂ� MATEĹ�SKĂ� Ĺ KOLA OPUS, O.P.S._inspection_report.txt already processed. Skipping...\n",
      "File 600000265_2022_SOUKROMĂ� MATEĹ�SKĂ� Ĺ KOLA OPUS, O.P.S._inspection_report.txt already processed. Skipping...\n",
      "File 600000273_2003_SoukromĂˇ mateĹ™skĂˇ Ĺˇkola  KORĂ�LEK , spol. s r.o._inspection_report.txt already processed. Skipping...\n",
      "File 600000273_2017_SoukromĂˇ mateĹ™skĂˇ Ĺˇkola  KORĂ�LEK , spol. s r.o._inspection_report.txt already processed. Skipping...\n",
      "File 600000273_2023_SoukromĂˇ mateĹ™skĂˇ Ĺˇkola  KORĂ�LEK , spol. s r.o._inspection_report.txt already processed. Skipping...\n",
      "File 600000290_2015_KatolickĂˇ mateĹ™skĂˇ Ĺˇkola sv. Klimenta_inspection_report.txt already processed. Skipping...\n",
      "File 600000290_2023_KatolickĂˇ mateĹ™skĂˇ Ĺˇkola sv. Klimenta_inspection_report.txt already processed. Skipping...\n",
      "File 600000303_2018_CĂ­rkevnĂ­ mateĹ™skĂˇ Ĺˇkola Laura_inspection_report.txt already processed. Skipping...\n",
      "File 600000311_2017_MateĹ™skĂˇ Ĺˇkola - Pro Family s.r.o._inspection_report.txt already processed. Skipping...\n",
      "File 600000311_2024_MateĹ™skĂˇ Ĺˇkola - Pro Family s.r.o._inspection_report.txt already processed. Skipping...\n",
      "File 600000338_2021_MateĹ™skĂˇ Ĺˇkola BERUĹ KA, s.r.o._inspection_report.txt already processed. Skipping...\n",
      "File 600000346_2018_ARCHA zĂˇkladnĂ­ Ĺˇkola a mateĹ™skĂˇ Ĺˇkola pĹ™i CĂ­rkvi ÄŤeskoslovenskĂ© husitskĂ©_inspection_report.txt already processed. Skipping...\n",
      "File 600000354_2018_DÄ›tskĂ˝ svÄ›t - mateĹ™skĂˇ Ĺˇkola s.r.o._inspection_report.txt already processed. Skipping...\n",
      "File 600000362_2018_KatolickĂˇ mateĹ™skĂˇ Ĺˇkola_inspection_report.txt already processed. Skipping...\n",
      "File 600000371_2019_CĂ­rkevnĂ­ mateĹ™skĂˇ Ĺˇkola Radost_inspection_report.txt already processed. Skipping...\n",
      "File 600000397_2019_SoukromĂˇ mateĹ™skĂˇ Ĺˇkola, o.p.s._inspection_report.txt already processed. Skipping...\n",
      "File 600000427_2021_MateĹ™skĂˇ Ĺˇkola Ĺ�EPOVANKA, o.p.s._inspection_report.txt already processed. Skipping...\n",
      "File 600000435_2021_SoukromĂˇ mateĹ™skĂˇ Ĺˇkola SEDMIKRĂ�SKA, s.r.o._inspection_report.txt already processed. Skipping...\n",
      "File 600000451_2016_CĂ­rkevnĂ­ mateĹ™skĂˇ Ĺˇkola ÄŚeskĂ© BudÄ›jovice, LipenskĂˇ 3_inspection_report.txt already processed. Skipping...\n",
      "File 600000460_2021_CĂ­rkevnĂ­ mateĹ™skĂˇ Ĺˇkola U sv. Josefa_inspection_report.txt already processed. Skipping...\n",
      "File 600000478_2016_II. soukromĂˇ mateĹ™skĂˇ Ĺˇkola SlunĂ­ÄŤko, s.r.o._inspection_report.txt already processed. Skipping...\n",
      "File 600000494_2017_CĂ­rkevnĂ­ mateĹ™skĂˇ Ĺˇkola JonĂˇĹˇ_inspection_report.txt already processed. Skipping...\n",
      "File 600000494_2024_CĂ­rkevnĂ­ mateĹ™skĂˇ Ĺˇkola JonĂˇĹˇ_inspection_report.txt already processed. Skipping...\n",
      "File 600000516_2017_MateĹ™skĂˇ Ĺˇkola SLUNĂŤÄŚKO VodĹ�any s.r.o._inspection_report.txt already processed. Skipping...\n",
      "File 600000524_2016_CĂ­rkevnĂ­ mateĹ™skĂˇ Ĺˇkola RybiÄŤka_inspection_report.txt already processed. Skipping...\n",
      "File 600000524_2024_CĂ­rkevnĂ­ mateĹ™skĂˇ Ĺˇkola RybiÄŤka_inspection_report.txt already processed. Skipping...\n",
      "File 600000532_2016_MATEĹ�SKĂ� Ĺ KOLA PRAMĂŤNEK, v.o.s._inspection_report.txt already processed. Skipping...\n",
      "File 600000532_2022_MATEĹ�SKĂ� Ĺ KOLA PRAMĂŤNEK, v.o.s._inspection_report.txt already processed. Skipping...\n",
      "File 600000541_2014_MateĹ™skĂˇ Ĺˇkola HARMONIE spol. s r.o._inspection_report.txt already processed. Skipping...\n",
      "File 600000541_2021_MateĹ™skĂˇ Ĺˇkola HARMONIE spol. s r.o._inspection_report.txt already processed. Skipping...\n",
      "File 600000567_2019_MateĹ™skĂˇ Ĺˇkola - BERUĹ KA v.o.s._inspection_report.txt already processed. Skipping...\n",
      "File 600000575_2019_SoukromĂˇ mateĹ™skĂˇ Ĺˇkola KVĂŤTKO, s.r.o._inspection_report.txt already processed. Skipping...\n",
      "File 600000591_2019_SoukromĂˇ mateĹ™skĂˇ Ĺˇkola MotĂ˝lek v.o.s._inspection_report.txt already processed. Skipping...\n",
      "File 600000621_2019_II. mateĹ™skĂˇ Ĺˇkola Preciosa, o.p.s._inspection_report.txt already processed. Skipping...\n",
      "File 600000630_2017_SoukromĂˇ mateĹ™skĂˇ Ĺˇkola MateĹ™inka s.r.o. Louny, HolĂˇrkovy sady 2386_inspection_report.txt already processed. Skipping...\n",
      "File 600000648_2022_SoukromĂˇ mateĹ™skĂˇ Ĺˇkola, obecnÄ› prospÄ›ĹˇnĂˇ spoleÄŤnost_inspection_report.txt already processed. Skipping...\n",
      "File 600000664_2017_SoukromĂˇ mateĹ™skĂˇ Ĺˇkola Bambino, o.p.s., SvÄ›tlĂˇ nad SĂˇzavou, HaĹˇkova 129_inspection_report.txt already processed. Skipping...\n",
      "File 600000664_2024_SoukromĂˇ mateĹ™skĂˇ Ĺˇkola Bambino, o.p.s., SvÄ›tlĂˇ nad SĂˇzavou, HaĹˇkova 129_inspection_report.txt already processed. Skipping...\n",
      "File 600000729_2021_MateĹ™skĂˇ Ĺˇkola a zĂˇkladnĂ­ Ĺˇkola SlunĂ­ÄŤko - Montessori, s.r.o._inspection_report.txt already processed. Skipping...\n",
      "File 600000737_2015_MATEĹ�ĂŤDOUĹ KA - soukromĂˇ mateĹ™skĂˇ Ĺˇkola s.r.o._inspection_report.txt already processed. Skipping...\n",
      "File 600000770_2020_MateĹ™skĂˇ Ĺˇkola SlunĂ­ÄŤko, s.r.o._inspection_report.txt already processed. Skipping...\n",
      "File 600000818_2020_MateĹ™skĂˇ Ĺˇkola MATEĹ�INKA, s.r.o._inspection_report.txt already processed. Skipping...\n",
      "File 600000966_2017_MateĹ™skĂˇ Ĺˇkola MATEĹ�INKA s.r.o._inspection_report.txt already processed. Skipping...\n",
      "File 600000966_2024_MateĹ™skĂˇ Ĺˇkola MATEĹ�INKA s.r.o._inspection_report.txt already processed. Skipping...\n",
      "File 600000982_2018_MATEĹ�SKĂ� Ĺ KOLA PALOVĂ�ÄŚEK, s.r.o._inspection_report.txt already processed. Skipping...\n",
      "File 600000982_2024_MATEĹ�SKĂ� Ĺ KOLA PALOVĂ�ÄŚEK, s.r.o._inspection_report.txt already processed. Skipping...\n",
      "File 600000991_2017_MateĹ™skĂˇ Ĺˇkola novojiÄŤĂ­nskĂˇ BeruĹˇka, spol. s r.o._inspection_report.txt already processed. Skipping...\n",
      "File 600000991_2023_MateĹ™skĂˇ Ĺˇkola novojiÄŤĂ­nskĂˇ BeruĹˇka, spol. s r.o._inspection_report.txt already processed. Skipping...\n",
      "File 600001008_2017_CĂ­rkevnĂ­ mateĹ™skĂˇ Ĺˇkola LudgeĹ™ovice, NĂˇdraĹľnĂ­ 495_inspection_report.txt already processed. Skipping...\n",
      "File 600001008_2023_CĂ­rkevnĂ­ mateĹ™skĂˇ Ĺˇkola LudgeĹ™ovice, NĂˇdraĹľnĂ­ 495_inspection_report.txt already processed. Skipping...\n",
      "File 600001016_2014_INĹˇkolka s.r.o._inspection_report.txt already processed. Skipping...\n",
      "File 600001016_2021_INĹˇkolka s.r.o._inspection_report.txt already processed. Skipping...\n",
      "File 600001032_2017_MateĹ™skĂˇ Ĺˇkola A & T s.r.o._inspection_report.txt already processed. Skipping...\n",
      "File 600001059_2019_Prima mateĹ™skĂˇ Ĺˇkola, s.r.o._inspection_report.txt already processed. Skipping...\n",
      "File 600001075_2014_SoukromĂˇ mateĹ™skĂˇ Ĺˇkola Ĺ tÄ›pĂˇn, o.p.s._inspection_report.txt already processed. Skipping...\n",
      "File 600001075_2021_SoukromĂˇ mateĹ™skĂˇ Ĺˇkola Ĺ tÄ›pĂˇn, o.p.s._inspection_report.txt already processed. Skipping...\n",
      "File 600001083_2016_ZĂˇkladnĂ­ Ĺˇkola sv. VorĹˇily v Praze_inspection_report.txt already processed. Skipping...\n",
      "File 600001083_2023_ZĂˇkladnĂ­ Ĺˇkola sv. VorĹˇily v Praze_inspection_report.txt already processed. Skipping...\n",
      "File 600001091_2016_VeselĂˇ Ĺˇkola - cĂ­rkevnĂ­ zĂˇkladnĂ­ Ĺˇkola a zĂˇkladnĂ­ umÄ›leckĂˇ Ĺˇkola_inspection_report.txt already processed. Skipping...\n",
      "File 600001091_2019_VeselĂˇ Ĺˇkola - cĂ­rkevnĂ­ zĂˇkladnĂ­ Ĺˇkola a zĂˇkladnĂ­ umÄ›leckĂˇ Ĺˇkola_inspection_report.txt already processed. Skipping...\n",
      "File 600001091_2024_VeselĂˇ Ĺˇkola - cĂ­rkevnĂ­ zĂˇkladnĂ­ Ĺˇkola a zĂˇkladnĂ­ umÄ›leckĂˇ Ĺˇkola_inspection_report.txt already processed. Skipping...\n",
      "File 600001113_2020_SoukromĂˇ zĂˇkladnĂ­ umÄ›leckĂˇ Ĺˇkola Music Art v.o.s._inspection_report.txt already processed. Skipping...\n",
      "File 600001121_2016_ZĂˇkladnĂ­ Ĺˇkola KlĂ­ÄŤek_inspection_report.txt already processed. Skipping...\n",
      "File 600001121_2024_ZĂˇkladnĂ­ Ĺˇkola KlĂ­ÄŤek_inspection_report.txt already processed. Skipping...\n",
      "File 600001130_2020_ZĂˇkladnĂ­ Ĺˇkola Duhovka, s.r.o._inspection_report.txt already processed. Skipping...\n",
      "File 600001148_2015_BRATRSKĂ� Ĺ KOLA - CĂŤRKEVNĂŤ ZĂ�KLADNĂŤ Ĺ KOLA_inspection_report.txt already processed. Skipping...\n",
      "File 600001148_2020_BRATRSKĂ� Ĺ KOLA - CĂŤRKEVNĂŤ ZĂ�KLADNĂŤ Ĺ KOLA_inspection_report.txt already processed. Skipping...\n",
      "File 600001172_2021_SoukromĂˇ zĂˇkladnĂ­ Ĺˇkola UNIVERZUM s.r.o._inspection_report.txt already processed. Skipping...\n",
      "File 600001199_2018_ZĂˇkladnĂ­ Ĺˇkola MaltĂ©zskĂ˝ch rytĂ­Ĺ™ĹŻ_inspection_report.txt already processed. Skipping...\n",
      "File 600001199_2024_ZĂˇkladnĂ­ Ĺˇkola MaltĂ©zskĂ˝ch rytĂ­Ĺ™ĹŻ_inspection_report.txt already processed. Skipping...\n",
      "File 600001237_2019_ZĂˇkladnĂ­ umÄ›leckĂˇ Ĺˇkola, ÄŚeskĂ˝ Brod, KollĂˇrova 419_inspection_report.txt already processed. Skipping...\n",
      "File 600001270_2015_ZĂˇkladnĂ­ Ĺˇkola Bernarda Bolzana obecnÄ› prospÄ›ĹˇnĂˇ spoleÄŤnost_inspection_report.txt already processed. Skipping...\n",
      "File 600001270_2022_ZĂˇkladnĂ­ Ĺˇkola Bernarda Bolzana obecnÄ› prospÄ›ĹˇnĂˇ spoleÄŤnost_inspection_report.txt already processed. Skipping...\n",
      "File 600001288_2018_CĂ­rkevnĂ­ zĂˇkladnĂ­ Ĺˇkola ORBIS-PICTUS, spol. s r.o._inspection_report.txt already processed. Skipping...\n",
      "File 600001296_2020_SoukromĂˇ zĂˇkladnĂ­ Ĺˇkola a mateĹ™skĂˇ Ĺˇkola AdĂ©lka, o.p.s._inspection_report.txt already processed. Skipping...\n",
      "File 600001300_2019_ZĂ�KLADNĂŤ Ĺ KOLA MARTINA LUTHERA, s.r.o._inspection_report.txt already processed. Skipping...\n",
      "File 600001318_2018_SoukromĂˇ zĂˇkladnĂ­ Ĺˇkola ELEMENTĂ�RIA, s.r.o._inspection_report.txt already processed. Skipping...\n",
      "File 600001318_2024_SoukromĂˇ zĂˇkladnĂ­ Ĺˇkola ELEMENTĂ�RIA, s.r.o._inspection_report.txt already processed. Skipping...\n",
      "File 600001334_2017_ZĂˇkladnĂ­ umÄ›leckĂˇ Ĺˇkola, Varnsdorf, NĂˇrodnĂ­ 512, pĹ™Ă­spÄ›vkovĂˇ organizace_inspection_report.txt already processed. Skipping...\n",
      "File 600001342_2018_ZĂˇkladnĂ­ umÄ›leckĂˇ Ĺˇkola, Rumburk, RĹŻĹľovĂˇ 31416, pĹ™Ă­spÄ›vkovĂˇ organizace_inspection_report.txt already processed. Skipping...\n",
      "File 600001351_2018_ZĂˇkladnĂ­ umÄ›leckĂˇ Ĺˇkola, DÄ›ÄŤĂ­n IV - Podmokly, ÄŚs. legiĂ­ 24329, pĹ™Ă­spÄ›vkovĂˇ organizace_inspection_report.txt already processed. Skipping...\n",
      "File 600001369_2015_ZĂˇkladnĂ­ Ĺˇkola AntonĂ­na BratrĹˇovskĂ©ho_inspection_report.txt already processed. Skipping...\n",
      "File 600001369_2022_ZĂˇkladnĂ­ Ĺˇkola AntonĂ­na BratrĹˇovskĂ©ho_inspection_report.txt already processed. Skipping...\n",
      "File 600001385_2015_KĹ™esĹĄanskĂˇ zĂˇkladnĂ­ Ĺˇkola a mateĹ™skĂˇ Ĺˇkola J. A. KomenskĂ©ho_inspection_report.txt already processed. Skipping...\n",
      "File 600001385_2023_KĹ™esĹĄanskĂˇ zĂˇkladnĂ­ Ĺˇkola a mateĹ™skĂˇ Ĺˇkola J. A. KomenskĂ©ho_inspection_report.txt already processed. Skipping...\n",
      "File 600001393_2018_LINGUA UNIVERSAL soukromĂˇ zĂˇkladnĂ­ Ĺˇkola a mateĹ™skĂˇ Ĺˇkola s.r.o._inspection_report.txt already processed. Skipping...\n",
      "File 600001423_2015_SportovnĂ­ soukromĂˇ zĂˇkladnĂ­ Ĺˇkola, s.r.o._inspection_report.txt already processed. Skipping...\n",
      "File 600001423_2023_SportovnĂ­ soukromĂˇ zĂˇkladnĂ­ Ĺˇkola, s.r.o._inspection_report.txt already processed. Skipping...\n",
      "File 600001431_2019_BiskupskĂ© gymnĂˇzium, ZĂˇkladnĂ­ Ĺˇkola a MateĹ™skĂˇ Ĺˇkola Bohosudov_inspection_report.txt already processed. Skipping...\n",
      "File 600001440_2017_ZĂˇkladnĂ­ umÄ›leckĂˇ Ĺˇkola Evy RandovĂ©, ĂšstĂ­ nad Labem, W. Churchilla 4, pĹ™Ă­spÄ›vkovĂˇ organizace_inspection_report.txt already processed. Skipping...\n",
      "File 600001466_2017_PrvnĂ­ soukromĂˇ zĂˇkladnĂ­ Ĺˇkola v Hradci KrĂˇlovĂ©, s.r.o._inspection_report.txt already processed. Skipping...\n",
      "File 600001474_2015_ZĂˇkladnĂ­ Ĺˇkola Mozaika, o.p.s. Rychnov nad KnÄ›Ĺľnou_inspection_report.txt already processed. Skipping...\n",
      "File 600001474_2022_ZĂˇkladnĂ­ Ĺˇkola Mozaika, o.p.s. Rychnov nad KnÄ›Ĺľnou_inspection_report.txt already processed. Skipping...\n",
      "Text preprocessing complete.\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 5.3 Transform and reduce\n",
    "The following code is designed to process textual data by transforming it into numerical features and reducing its dimensionality for further analysis.\n",
    "\n",
    "- **File Processing**: The script starts by setting up paths to directories where the processed text files and results will be stored. It reads in the processed text files and limits the number of files to process based on a predefined chunk size and optional processing limit.\n",
    "\n",
    "- **TF-IDF Vectorization**: The code uses the `TfidfVectorizer` from the `sklearn` library to transform the processed text documents into a TF-IDF matrix. This matrix represents the importance of words within the documents. The vocabulary is established by fitting the vectorizer on a subset or the entirety of the text data.\n",
    "\n",
    "- **Chunk Processing**: The script processes the text files in chunks to manage memory usage efficiently. Each chunk of documents is transformed into a TF-IDF matrix, which is then saved as a sparse matrix. Metadata (such as school identifiers and report years) is also saved for each chunk.\n",
    "\n",
    "- **Dimensionality Reduction using PCA**: The TF-IDF matrices from all chunks are loaded and concatenated into a single matrix. The `PCA` (Principal Component Analysis) from the `sklearn` library is then applied to reduce the dimensionality of the data, retaining only the most significant components. This step is crucial for making the data more manageable and enhancing the performance of machine learning models.\n",
    "\n",
    "- **Saving Results**: The reduced features, along with metadata, are saved to a CSV file. The script also visualizes the explained variance by each principal component through scree plots and cumulative explained variance plots. Additionally, a 2D scatter plot and a pairplot of the first few principal components are generated to visualize the data's structure in the reduced feature space.\n",
    "\n",
    "- **Visualization**: Finally, the script includes visualizations to assess how much variance each principal component explains and to explore relationships between the first few principal components.\n"
   ],
   "id": "a5adb487532a2076"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "!!! The uploaded files do not include the original data (for size reasons), only transformed and reduced output of the following code. So do not run this part of the code if you don't want to replace the full data with transformation and reduction done only from the newly downloaded files. !!!",
   "id": "35387db551056ff4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# !python transform_reduce.py\n",
    "# \n",
    "# os.chdir('C:/++4630/++ University, education/03 -- Tilburg_v02/Data Science/plots')\n",
    "# \n",
    "# display(Image(filename='Cumulative Explained Variance.png'))\n",
    "# \n",
    "# \n",
    "# os.chdir('C:/++4630/++ University, education/03 -- Tilburg_v02/Data Science/plots')\n"
   ],
   "id": "2d8ac883db58e378"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 5.4 First analysis and naive regression\n",
    "The following code is used to load, filter, and analyze data related to Czech school inspections. It performs several key tasks, including merging datasets, calculating correlations and then applying a Lasso regression model.\n",
    "\n",
    "### Data Loading and Preprocessing\n",
    "\n",
    "- **Loading Data**: The code begins by loading a CSV file containing school inspection data. It then renames a column to ensure consistency with the processed features dataset.\n",
    "\n",
    "- **Filtering Data**: The code filters out special schools and neighboring school data to focus only on the relevant institutions. It converts the school identifier ('redizo') to a string for consistency.\n",
    "\n",
    "- **Merging Datasets**: The code loads processed PCA features and merges them with the filtered data. It calculates the distance in years to match the closest inspection report for each school and adds this information to the dataset.\n",
    "\n",
    "- **Handling Missing Data**: The code drops rows with missing values to ensure data completeness before saving the complete and filtered datasets to CSV files.\n",
    "\n",
    "### Data Analysis\n",
    "\n",
    "- **Correlation Analysis**: The code selects numeric columns from the filtered dataset and calculates the correlation between the principal components (PCs) and the target variable ('value'). It then visualizes these correlations using bar plots for different groups of PCs.\n",
    "\n",
    "- **Lasso Regression**: The code defines the PCs as features and the 'value' as the target variable. It splits the data into training and testing sets and applies a Lasso regression model with cross-validation to find the optimal regularization parameter (alpha). The model's performance is evaluated using Mean Squared Error (MSE) and R-squared (R²) metrics.\n",
    "\n",
    "- **Visualization**: The code generates several plots, including:\n",
    "  - A scatter plot of true vs. predicted values to assess the model's performance.\n",
    "  - A plot of Lasso coefficients to visualize the importance of each feature in the model."
   ],
   "id": "5340ef1d2eb82319"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Explanation of Variables and Their Significance\n",
    "Following inforamtion is from the data source:<br>\n",
    "\n",
    "The variable `value` represents the probability that an expert would classify a particular school as disadvantaged. This probability is derived from a Bayesian model that estimates how likely it is that an expert, with local knowledge, would perceive the school as facing disadvantages.\n",
    "\n",
    "#### Understanding the Variables `bound` and `nschool`\n",
    "\n",
    "- **`nschool`**: This variable indicates whether the value pertains to the specific school identified by `redizo` or one of the ten geographically nearest schools (measured as the crow flies) related to this school. A value of `0` indicates that the data is for the school itself, while other values correspond to nearby schools ranked by physical proximity. If you are only interested in the specific school, you can filter the data with `nschool == 0`.\n",
    "\n",
    "- **`bound`**: This variable indicates whether the reported value represents the upper or lower bound of the Bayesian 95% credible interval. This interval provides a range in which the true probability is likely to fall, given the uncertainty in the estimation process.\n",
    "\n",
    "  - The **lower bound** (`bound == 'lower'`) corresponds to the 2.5% quantile of the posterior distribution, indicating the lower end of the credible interval.\n",
    "  - The **upper bound** (`bound == 'upper'`) corresponds to the 97.5% quantile, indicating the upper end.\n",
    "\n",
    "The credible interval reflects the uncertainty surrounding the expert’s decision-making process, influenced by factors such as the school's size and the number of observations available. For practical purposes, a school is considered disadvantaged if the upper bound exceeds 0.83, based on empirical analysis which balanced sensitivity and specificity effectively with this threshold.\n"
   ],
   "id": "bb008cfc6ae21637"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "!python analyse.py\n",
    "\n",
    "#currently other plots are muted to not overwhelm this notebook\n",
    "os.chdir('C:/++4630/++ University, education/03 -- Tilburg_v02/Data Science/plots')\n",
    "display(Image(filename='plots/True vs Predicted Values (Lasso Regression).png'))\n",
    "os.chdir('C:/++4630/++ University, education/03 -- Tilburg_v02/Data Science/scripts')"
   ],
   "id": "87cddc52ae6b4b45"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T17:28:06.035600Z",
     "start_time": "2024-08-16T17:27:18.316756Z"
    }
   },
   "cell_type": "code",
   "source": "!python scripts\\neural_network.py",
   "id": "d1ef64af43d25d9e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m1:03\u001B[0m 2s/step - loss: 0.0817\n",
      "\u001B[1m27/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37mâ”�â”�\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0485 \n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 9ms/step - loss: 0.0477 - val_loss: 0.0313\n",
      "Epoch 2/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 0.0254\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0207 - val_loss: 0.0266\n",
      "Epoch 3/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 0.0081\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.0099 - val_loss: 0.0264\n",
      "Epoch 4/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - loss: 0.0077\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0071 - val_loss: 0.0269\n",
      "Epoch 5/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - loss: 0.0055\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0044 - val_loss: 0.0276\n",
      "Epoch 6/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 0.0020\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0026 - val_loss: 0.0282\n",
      "Epoch 7/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 0.0011\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0017 - val_loss: 0.0283\n",
      "Epoch 8/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m1s\u001B[0m 40ms/step - loss: 0.0018\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0015 - val_loss: 0.0304\n",
      "Epoch 9/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 8.5585e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0011 - val_loss: 0.0307\n",
      "Epoch 10/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 0.0020\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.0010 - val_loss: 0.0308\n",
      "Epoch 11/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 4.9811e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.0011 - val_loss: 0.0298\n",
      "Epoch 12/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m1s\u001B[0m 36ms/step - loss: 3.6136e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 7.9239e-04 - val_loss: 0.0293\n",
      "Epoch 13/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 0.0023\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0011 - val_loss: 0.0306\n",
      "Epoch 14/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - loss: 0.0011\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0011 - val_loss: 0.0296\n",
      "Epoch 15/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 0.0011\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 8.0910e-04 - val_loss: 0.0299\n",
      "Epoch 16/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 0.0013\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 6.1766e-04 - val_loss: 0.0284\n",
      "Epoch 17/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 3.1189e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 6.6983e-04 - val_loss: 0.0308\n",
      "Epoch 18/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 1.7577e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 7.7488e-04 - val_loss: 0.0294\n",
      "Epoch 19/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 0.0010\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 8.1491e-04 - val_loss: 0.0298\n",
      "Epoch 20/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - loss: 0.0010\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 7.8207e-04 - val_loss: 0.0297\n",
      "Epoch 21/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - loss: 1.5611e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 4.5820e-04 - val_loss: 0.0290\n",
      "Epoch 22/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 2.8108e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 4.9111e-04 - val_loss: 0.0296\n",
      "Epoch 23/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - loss: 2.8540e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 4.5265e-04 - val_loss: 0.0288\n",
      "Epoch 24/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 9.9291e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 5.0474e-04 - val_loss: 0.0290\n",
      "Epoch 25/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 1.6108e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 4.9573e-04 - val_loss: 0.0284\n",
      "Epoch 26/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 5.7268e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 4.4776e-04 - val_loss: 0.0294\n",
      "Epoch 27/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 2.1432e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 4.6477e-04 - val_loss: 0.0287\n",
      "Epoch 28/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - loss: 2.8162e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 3.5861e-04 - val_loss: 0.0287\n",
      "Epoch 29/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - loss: 3.4480e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 4.0814e-04 - val_loss: 0.0288\n",
      "Epoch 30/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 1.7525e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.7237e-04 - val_loss: 0.0289\n",
      "Epoch 31/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 1.2086e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.9382e-04 - val_loss: 0.0290\n",
      "Epoch 32/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - loss: 2.3516e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 3.1950e-04 - val_loss: 0.0290\n",
      "Epoch 33/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 4.4972e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 4.2368e-04 - val_loss: 0.0281\n",
      "Epoch 34/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - loss: 2.3415e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 3.6021e-04 - val_loss: 0.0291\n",
      "Epoch 35/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 9.7457e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 3.2628e-04 - val_loss: 0.0280\n",
      "Epoch 36/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 1.8883e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 4.7386e-04 - val_loss: 0.0295\n",
      "Epoch 37/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - loss: 2.2418e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 3.9104e-04 - val_loss: 0.0285\n",
      "Epoch 38/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - loss: 2.4182e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 3.8172e-04 - val_loss: 0.0284\n",
      "Epoch 39/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 1.3890e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 4.9664e-04 - val_loss: 0.0284\n",
      "Epoch 40/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 5.0912e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 4.7772e-04 - val_loss: 0.0282\n",
      "Epoch 41/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 1.7310e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 4.2789e-04 - val_loss: 0.0288\n",
      "Epoch 42/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - loss: 2.3968e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 4.6595e-04 - val_loss: 0.0289\n",
      "Epoch 43/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - loss: 8.5297e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 6.8921e-04 - val_loss: 0.0282\n",
      "Epoch 44/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 1.9508e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 3.7760e-04 - val_loss: 0.0290\n",
      "Epoch 45/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 2.8122e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 4.6721e-04 - val_loss: 0.0278\n",
      "Epoch 46/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 0.0027\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 6.9889e-04 - val_loss: 0.0284\n",
      "Epoch 47/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 9.2356e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.3706e-04 - val_loss: 0.0275\n",
      "Epoch 48/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 2.1405e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 3.6929e-04 - val_loss: 0.0288\n",
      "Epoch 49/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 2.7352e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 4.7390e-04 - val_loss: 0.0282\n",
      "Epoch 50/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 2.0379e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 3.8887e-04 - val_loss: 0.0284\n",
      "Epoch 51/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 1.6788e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 3.1637e-04 - val_loss: 0.0279\n",
      "Epoch 52/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 2.4153e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 3.0218e-04 - val_loss: 0.0280\n",
      "Epoch 53/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - loss: 9.7383e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.8651e-04 - val_loss: 0.0279\n",
      "Epoch 54/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - loss: 1.1163e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.5805e-04 - val_loss: 0.0282\n",
      "Epoch 55/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - loss: 3.0213e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.4935e-04 - val_loss: 0.0282\n",
      "Epoch 56/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - loss: 2.1832e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.9907e-04 - val_loss: 0.0280\n",
      "Epoch 57/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m1s\u001B[0m 39ms/step - loss: 2.1011e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.4904e-04 - val_loss: 0.0280\n",
      "Epoch 58/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - loss: 9.6812e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.0272e-04 - val_loss: 0.0278\n",
      "Epoch 59/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - loss: 0.0010\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 4.1969e-04 - val_loss: 0.0280\n",
      "Epoch 60/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m1s\u001B[0m 46ms/step - loss: 1.6094e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 4.0796e-04 - val_loss: 0.0278\n",
      "Epoch 61/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m1s\u001B[0m 40ms/step - loss: 1.2808e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 3.3288e-04 - val_loss: 0.0280\n",
      "Epoch 62/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - loss: 1.3113e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.8407e-04 - val_loss: 0.0279\n",
      "Epoch 63/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m1s\u001B[0m 38ms/step - loss: 1.5090e-04\n",
      "\u001B[1m13/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 3.2750e-04 \n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 3.2756e-04 - val_loss: 0.0280\n",
      "Epoch 64/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 1.9256e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 3.5063e-04 - val_loss: 0.0273\n",
      "Epoch 65/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m1s\u001B[0m 40ms/step - loss: 7.6498e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 3.0590e-04 - val_loss: 0.0283\n",
      "Epoch 66/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m1s\u001B[0m 51ms/step - loss: 1.4653e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 3.0168e-04 - val_loss: 0.0271\n",
      "Epoch 67/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - loss: 7.8068e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.7482e-04 - val_loss: 0.0277\n",
      "Epoch 68/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - loss: 8.8591e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.9813e-04 - val_loss: 0.0276\n",
      "Epoch 69/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m1s\u001B[0m 39ms/step - loss: 3.2320e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.2467e-04 - val_loss: 0.0271\n",
      "Epoch 70/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - loss: 1.9890e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 3.5046e-04 - val_loss: 0.0277\n",
      "Epoch 71/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 2.6779e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 3.0015e-04 - val_loss: 0.0273\n",
      "Epoch 72/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 2.4243e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 3.3126e-04 - val_loss: 0.0278\n",
      "Epoch 73/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - loss: 1.3599e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 4.1598e-04 - val_loss: 0.0273\n",
      "Epoch 74/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - loss: 1.1748e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 2.9399e-04 - val_loss: 0.0280\n",
      "Epoch 75/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 1.8819e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 3.1531e-04 - val_loss: 0.0269\n",
      "Epoch 76/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 4.7357e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 3.6922e-04 - val_loss: 0.0274\n",
      "Epoch 77/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m1s\u001B[0m 57ms/step - loss: 6.6802e-05\n",
      "\u001B[1m11/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 7.9844e-04 \n",
      "\u001B[1m23/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37mâ”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 6.9277e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 6.4500e-04 - val_loss: 0.0274\n",
      "Epoch 78/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m3s\u001B[0m 115ms/step - loss: 2.8767e-04\n",
      "\u001B[1m10/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 2.6300e-04  \n",
      "\u001B[1m20/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37mâ”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 3.0675e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 3.3830e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 3.3959e-04 - val_loss: 0.0274\n",
      "Epoch 79/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m3s\u001B[0m 137ms/step - loss: 0.0019\n",
      "\u001B[1m 9/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 8.2863e-04\n",
      "\u001B[1m16/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 6.5828e-04\n",
      "\u001B[1m24/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37mâ”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 5.5807e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 13ms/step - loss: 5.1336e-04 - val_loss: 0.0274\n",
      "Epoch 80/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m4s\u001B[0m 149ms/step - loss: 8.7358e-05\n",
      "\u001B[1m 8/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�\u001B[0m\u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 2.2832e-04  \n",
      "\u001B[1m16/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 2.7745e-04\n",
      "\u001B[1m26/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37mâ”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 3.0727e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 3.1337e-04 - val_loss: 0.0273\n",
      "Epoch 81/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 1.2881e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.3380e-04 - val_loss: 0.0274\n",
      "Epoch 82/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - loss: 3.0264e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.6046e-04 - val_loss: 0.0274\n",
      "Epoch 83/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 1.2913e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 2.0384e-04 - val_loss: 0.0266\n",
      "Epoch 84/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - loss: 6.0447e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 2.7854e-04 - val_loss: 0.0276\n",
      "Epoch 85/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - loss: 1.1418e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 1.6706e-04 - val_loss: 0.0274\n",
      "Epoch 86/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m1s\u001B[0m 51ms/step - loss: 5.6160e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 2.7933e-04 - val_loss: 0.0273\n",
      "Epoch 87/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m1s\u001B[0m 42ms/step - loss: 1.5931e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.1656e-04 - val_loss: 0.0269\n",
      "Epoch 88/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 1.0290e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.7515e-04 - val_loss: 0.0275\n",
      "Epoch 89/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m1s\u001B[0m 52ms/step - loss: 1.6957e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 2.0353e-04 - val_loss: 0.0264\n",
      "Epoch 90/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - loss: 2.3970e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 2.3561e-04 - val_loss: 0.0274\n",
      "Epoch 91/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - loss: 5.7288e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.8531e-04 - val_loss: 0.0265\n",
      "Epoch 92/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - loss: 1.4248e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.1727e-04 - val_loss: 0.0274\n",
      "Epoch 93/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 4.1466e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 3.0383e-04 - val_loss: 0.0266\n",
      "Epoch 94/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 5.8539e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 1.4052e-04 - val_loss: 0.0271\n",
      "Epoch 95/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 8.9385e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 1.8969e-04 - val_loss: 0.0266\n",
      "Epoch 96/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 1.2276e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 1.3966e-04 - val_loss: 0.0272\n",
      "Epoch 97/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m1s\u001B[0m 42ms/step - loss: 8.8628e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 2.0142e-04 - val_loss: 0.0265\n",
      "Epoch 98/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 0.0012\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 2.9617e-04 - val_loss: 0.0278\n",
      "Epoch 99/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - loss: 6.7107e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.1474e-04 - val_loss: 0.0263\n",
      "Epoch 100/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - loss: 1.0881e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 2.4441e-04 - val_loss: 0.0269\n",
      "Epoch 101/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 8.8612e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 2.7037e-04 - val_loss: 0.0266\n",
      "Epoch 102/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - loss: 3.7141e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 3.3128e-04 - val_loss: 0.0270\n",
      "Epoch 103/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - loss: 1.7680e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.5096e-04 - val_loss: 0.0264\n",
      "Epoch 104/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - loss: 1.9209e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.9006e-04 - val_loss: 0.0262\n",
      "Epoch 105/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 1.6786e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.9580e-04 - val_loss: 0.0271\n",
      "Epoch 106/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 5.9106e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 3.5314e-04 - val_loss: 0.0267\n",
      "Epoch 107/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 1.3056e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 4.2603e-04 - val_loss: 0.0267\n",
      "Epoch 108/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - loss: 2.4913e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 2.6717e-04 - val_loss: 0.0265\n",
      "Epoch 109/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m1s\u001B[0m 39ms/step - loss: 1.2434e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.3386e-04 - val_loss: 0.0267\n",
      "Epoch 110/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - loss: 1.3788e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.9556e-04 - val_loss: 0.0263\n",
      "Epoch 111/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - loss: 1.4519e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.3948e-04 - val_loss: 0.0261\n",
      "Epoch 112/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - loss: 7.1285e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 1.4182e-04 - val_loss: 0.0267\n",
      "Epoch 113/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m1s\u001B[0m 41ms/step - loss: 7.0844e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.2628e-04 - val_loss: 0.0257\n",
      "Epoch 114/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 1.2044e-04\n",
      "\u001B[1m25/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37mâ”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.8080e-04 \n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 1.7971e-04 - val_loss: 0.0262\n",
      "Epoch 115/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 6.2799e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.1368e-04 - val_loss: 0.0256\n",
      "Epoch 116/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 4.5020e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.1371e-04 - val_loss: 0.0264\n",
      "Epoch 117/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - loss: 6.2735e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.4775e-04 - val_loss: 0.0257\n",
      "Epoch 118/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 4.1269e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.2556e-04 - val_loss: 0.0263\n",
      "Epoch 119/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - loss: 7.1955e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 1.1091e-04 - val_loss: 0.0258\n",
      "Epoch 120/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 1.2404e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 1.3878e-04 - val_loss: 0.0261\n",
      "Epoch 121/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - loss: 5.4284e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.0503e-04 - val_loss: 0.0257\n",
      "Epoch 122/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - loss: 6.7220e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.4704e-04 - val_loss: 0.0265\n",
      "Epoch 123/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 7.1946e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.0998e-04 - val_loss: 0.0255\n",
      "Epoch 124/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - loss: 4.2265e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 1.2646e-04 - val_loss: 0.0263\n",
      "Epoch 125/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - loss: 1.5219e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.7157e-04 - val_loss: 0.0256\n",
      "Epoch 126/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - loss: 9.9829e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.6283e-04 - val_loss: 0.0260\n",
      "Epoch 127/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - loss: 2.4291e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.4999e-04 - val_loss: 0.0261\n",
      "Epoch 128/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - loss: 2.7114e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.3873e-04 - val_loss: 0.0260\n",
      "Epoch 129/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 1.6650e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.3225e-04 - val_loss: 0.0260\n",
      "Epoch 130/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 1.6479e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 3.1508e-04 - val_loss: 0.0256\n",
      "Epoch 131/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 2.5008e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 3.1724e-04 - val_loss: 0.0273\n",
      "Epoch 132/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 7.4706e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 5.0575e-04 - val_loss: 0.0263\n",
      "Epoch 133/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m1s\u001B[0m 42ms/step - loss: 2.6593e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 7.0473e-04 - val_loss: 0.0261\n",
      "Epoch 134/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - loss: 4.1375e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 6.5980e-04 - val_loss: 0.0260\n",
      "Epoch 135/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - loss: 0.0011\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 9.7217e-04 - val_loss: 0.0253\n",
      "Epoch 136/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m1s\u001B[0m 37ms/step - loss: 5.3015e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 7.9986e-04 - val_loss: 0.0268\n",
      "Epoch 137/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 6.2162e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 7.1231e-04 - val_loss: 0.0253\n",
      "Epoch 138/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 1.4604e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 4.9318e-04 - val_loss: 0.0254\n",
      "Epoch 139/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 1.7599e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 3.8874e-04 - val_loss: 0.0255\n",
      "Epoch 140/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - loss: 1.7752e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.8237e-04 - val_loss: 0.0257\n",
      "Epoch 141/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - loss: 1.0433e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.8985e-04 - val_loss: 0.0252\n",
      "Epoch 142/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m1s\u001B[0m 38ms/step - loss: 3.5187e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 9.1940e-05 - val_loss: 0.0255\n",
      "Epoch 143/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 2.0979e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 8.6040e-05 - val_loss: 0.0253\n",
      "Epoch 144/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 1.1898e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 4.5098e-05 - val_loss: 0.0255\n",
      "Epoch 145/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - loss: 1.6278e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 6.2032e-05 - val_loss: 0.0254\n",
      "Epoch 146/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 3.0576e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 5.9983e-05 - val_loss: 0.0254\n",
      "Epoch 147/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - loss: 1.2306e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 5.7334e-05 - val_loss: 0.0253\n",
      "Epoch 148/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 1.1042e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 4.9626e-05 - val_loss: 0.0255\n",
      "Epoch 149/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 3.5415e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 5.5701e-05 - val_loss: 0.0249\n",
      "Epoch 150/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m1s\u001B[0m 36ms/step - loss: 2.9901e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 5.6246e-05 - val_loss: 0.0257\n",
      "Epoch 151/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 2.5842e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 5.0493e-05 - val_loss: 0.0251\n",
      "Epoch 152/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - loss: 5.2747e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 5.4464e-05 - val_loss: 0.0255\n",
      "Epoch 153/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 1.2876e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 7.2826e-05 - val_loss: 0.0253\n",
      "Epoch 154/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - loss: 2.8133e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 3.5074e-05 - val_loss: 0.0256\n",
      "Epoch 155/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - loss: 2.7491e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 5.0532e-05 - val_loss: 0.0252\n",
      "Epoch 156/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - loss: 8.6430e-06\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 5.6686e-05 - val_loss: 0.0255\n",
      "Epoch 157/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 3.9263e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 4.5447e-05 - val_loss: 0.0254\n",
      "Epoch 158/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - loss: 4.1099e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 5.5660e-05 - val_loss: 0.0254\n",
      "Epoch 159/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 3.6169e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 4.5503e-05 - val_loss: 0.0252\n",
      "Epoch 160/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - loss: 2.4850e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 4.6594e-05 - val_loss: 0.0255\n",
      "Epoch 161/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 3.1580e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 6.5009e-05 - val_loss: 0.0254\n",
      "Epoch 162/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 1.7817e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 9.2921e-05 - val_loss: 0.0251\n",
      "Epoch 163/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 1.7997e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 8.2845e-05 - val_loss: 0.0253\n",
      "Epoch 164/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 6.4489e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 7.6149e-05 - val_loss: 0.0250\n",
      "Epoch 165/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - loss: 6.1308e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 7.3357e-05 - val_loss: 0.0251\n",
      "Epoch 166/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - loss: 5.7120e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 8.8381e-05 - val_loss: 0.0250\n",
      "Epoch 167/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - loss: 6.5025e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 8.0842e-05 - val_loss: 0.0252\n",
      "Epoch 168/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - loss: 3.8227e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 8.3043e-05 - val_loss: 0.0251\n",
      "Epoch 169/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - loss: 8.6579e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 1.0649e-04 - val_loss: 0.0255\n",
      "Epoch 170/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - loss: 1.6816e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.4730e-04 - val_loss: 0.0253\n",
      "Epoch 171/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - loss: 1.3799e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.7216e-04 - val_loss: 0.0251\n",
      "Epoch 172/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - loss: 8.8169e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.2252e-04 - val_loss: 0.0247\n",
      "Epoch 173/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - loss: 9.7922e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 9.9695e-05 - val_loss: 0.0251\n",
      "Epoch 174/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - loss: 1.0074e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.0735e-04 - val_loss: 0.0249\n",
      "Epoch 175/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - loss: 6.6729e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.0548e-04 - val_loss: 0.0249\n",
      "Epoch 176/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 1.4917e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.0262e-04 - val_loss: 0.0249\n",
      "Epoch 177/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - loss: 2.7658e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 8.6952e-05 - val_loss: 0.0250\n",
      "Epoch 178/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m1s\u001B[0m 37ms/step - loss: 8.0514e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 8.2831e-05 - val_loss: 0.0248\n",
      "Epoch 179/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - loss: 1.0041e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 9.5168e-05 - val_loss: 0.0248\n",
      "Epoch 180/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 6.0757e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 9.0357e-05 - val_loss: 0.0252\n",
      "Epoch 181/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m1s\u001B[0m 39ms/step - loss: 9.8703e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 9.4546e-05 - val_loss: 0.0244\n",
      "Epoch 182/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - loss: 5.8339e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 9.1963e-05 - val_loss: 0.0256\n",
      "Epoch 183/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - loss: 7.1746e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.6844e-04 - val_loss: 0.0253\n",
      "Epoch 184/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - loss: 3.6001e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 4.7543e-04 - val_loss: 0.0250\n",
      "Epoch 185/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - loss: 1.0934e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.3085e-04 - val_loss: 0.0249\n",
      "Epoch 186/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 7.3904e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 9.7385e-05 - val_loss: 0.0250\n",
      "Epoch 187/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 1.1981e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.2482e-04 - val_loss: 0.0248\n",
      "Epoch 188/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - loss: 5.7179e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.1429e-04 - val_loss: 0.0250\n",
      "Epoch 189/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - loss: 6.8757e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.0823e-04 - val_loss: 0.0253\n",
      "Epoch 190/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 2.4612e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.0707e-04 - val_loss: 0.0251\n",
      "Epoch 191/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - loss: 1.1521e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.6103e-04 - val_loss: 0.0246\n",
      "Epoch 192/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - loss: 1.1291e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.2997e-04 - val_loss: 0.0247\n",
      "Epoch 193/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 1.0924e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.4712e-04 - val_loss: 0.0249\n",
      "Epoch 194/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - loss: 1.0664e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.6776e-04 - val_loss: 0.0251\n",
      "Epoch 195/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m1s\u001B[0m 36ms/step - loss: 7.4926e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.7727e-04 - val_loss: 0.0258\n",
      "Epoch 196/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 1.3863e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 1.8818e-04 - val_loss: 0.0245\n",
      "Epoch 197/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 1.3263e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 1.7233e-04 - val_loss: 0.0250\n",
      "Epoch 198/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - loss: 8.3702e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 1.6122e-04 - val_loss: 0.0247\n",
      "Epoch 199/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 9.3570e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.3383e-04 - val_loss: 0.0255\n",
      "Epoch 200/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 3.3854e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.1910e-04 - val_loss: 0.0243\n",
      "Epoch 201/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 9.4784e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.3776e-04 - val_loss: 0.0249\n",
      "Epoch 202/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 1.9803e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.0590e-04 - val_loss: 0.0248\n",
      "Epoch 203/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 4.2155e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.1393e-04 - val_loss: 0.0247\n",
      "Epoch 204/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - loss: 1.0383e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.4762e-04 - val_loss: 0.0250\n",
      "Epoch 205/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 1.4199e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 1.1350e-04 - val_loss: 0.0243\n",
      "Epoch 206/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - loss: 9.7508e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 1.1124e-04 - val_loss: 0.0250\n",
      "Epoch 207/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - loss: 3.4122e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 7.9204e-05 - val_loss: 0.0247\n",
      "Epoch 208/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - loss: 8.2068e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 9.0150e-05 - val_loss: 0.0246\n",
      "Epoch 209/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - loss: 8.9650e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 9.9887e-05 - val_loss: 0.0250\n",
      "Epoch 210/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - loss: 9.8080e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 1.0891e-04 - val_loss: 0.0244\n",
      "Epoch 211/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 1.4889e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 9.1960e-05 - val_loss: 0.0248\n",
      "Epoch 212/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m1s\u001B[0m 37ms/step - loss: 8.2822e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 7.8236e-05 - val_loss: 0.0245\n",
      "Epoch 213/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 4.6830e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 9.2592e-05 - val_loss: 0.0246\n",
      "Epoch 214/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m1s\u001B[0m 40ms/step - loss: 8.8577e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.3503e-04 - val_loss: 0.0240\n",
      "Epoch 215/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - loss: 9.3129e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 9.7916e-05 - val_loss: 0.0247\n",
      "Epoch 216/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 1.0834e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.4779e-04 - val_loss: 0.0241\n",
      "Epoch 217/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - loss: 1.8974e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 1.5674e-04 - val_loss: 0.0253\n",
      "Epoch 218/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - loss: 3.0451e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 2.0185e-04 - val_loss: 0.0244\n",
      "Epoch 219/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - loss: 1.1598e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.7340e-04 - val_loss: 0.0241\n",
      "Epoch 220/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - loss: 2.0116e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.4805e-04 - val_loss: 0.0239\n",
      "Epoch 221/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m1s\u001B[0m 37ms/step - loss: 3.2550e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.3250e-04 - val_loss: 0.0246\n",
      "Epoch 222/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m1s\u001B[0m 36ms/step - loss: 1.0718e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.2493e-04 - val_loss: 0.0242\n",
      "Epoch 223/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 8.6734e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.0047e-04 - val_loss: 0.0245\n",
      "Epoch 224/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - loss: 7.7983e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 9.0962e-05 - val_loss: 0.0245\n",
      "Epoch 225/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 4.3689e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 8.9663e-05 - val_loss: 0.0244\n",
      "Epoch 226/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m1s\u001B[0m 39ms/step - loss: 5.6385e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 7.6506e-05 - val_loss: 0.0241\n",
      "Epoch 227/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 5.9016e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 6.7955e-05 - val_loss: 0.0242\n",
      "Epoch 228/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 7.0965e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 1.0914e-04 - val_loss: 0.0244\n",
      "Epoch 229/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - loss: 3.8021e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 1.8913e-04 - val_loss: 0.0238\n",
      "Epoch 230/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m1s\u001B[0m 37ms/step - loss: 1.6057e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 3.3354e-04 - val_loss: 0.0245\n",
      "Epoch 231/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 2.6247e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 5.4790e-04 - val_loss: 0.0238\n",
      "Epoch 232/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 3.3941e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 3.4529e-04 - val_loss: 0.0248\n",
      "Epoch 233/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - loss: 2.0040e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.6491e-04 - val_loss: 0.0240\n",
      "Epoch 234/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - loss: 3.1413e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.3974e-04 - val_loss: 0.0238\n",
      "Epoch 235/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - loss: 3.7253e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.2389e-04 - val_loss: 0.0237\n",
      "Epoch 236/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - loss: 1.2456e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.6920e-04 - val_loss: 0.0240\n",
      "Epoch 237/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - loss: 9.4110e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.3814e-04 - val_loss: 0.0241\n",
      "Epoch 238/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 6.9763e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 8.9972e-05 - val_loss: 0.0235\n",
      "Epoch 239/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 7.5095e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.0991e-04 - val_loss: 0.0243\n",
      "Epoch 240/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - loss: 1.1580e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.1494e-04 - val_loss: 0.0241\n",
      "Epoch 241/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 4.3494e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 8.5530e-05 - val_loss: 0.0239\n",
      "Epoch 242/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 8.9856e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 8.3064e-05 - val_loss: 0.0238\n",
      "Epoch 243/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - loss: 3.2220e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 7.3746e-05 - val_loss: 0.0238\n",
      "Epoch 244/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - loss: 7.4955e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 6.7798e-05 - val_loss: 0.0240\n",
      "Epoch 245/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - loss: 9.4439e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 5.9723e-05 - val_loss: 0.0232\n",
      "Epoch 246/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - loss: 3.4445e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 4.5546e-05 - val_loss: 0.0233\n",
      "Epoch 247/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - loss: 3.7995e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 4.9485e-05 - val_loss: 0.0235\n",
      "Epoch 248/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - loss: 4.5556e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 5.7068e-05 - val_loss: 0.0233\n",
      "Epoch 249/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 1.8037e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.6743e-05 - val_loss: 0.0238\n",
      "Epoch 250/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 3.6397e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 3.6296e-05 - val_loss: 0.0234\n",
      "Epoch 251/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 2.8951e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 3.1900e-05 - val_loss: 0.0237\n",
      "Epoch 252/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 4.9172e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.7874e-05 - val_loss: 0.0235\n",
      "Epoch 253/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - loss: 1.3169e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 2.7395e-05 - val_loss: 0.0235\n",
      "Epoch 254/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 1.5414e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 5.2879e-05 - val_loss: 0.0237\n",
      "Epoch 255/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 2.0147e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 3.1282e-05 - val_loss: 0.0234\n",
      "Epoch 256/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - loss: 1.3218e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 3.4137e-05 - val_loss: 0.0236\n",
      "Epoch 257/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - loss: 9.7897e-06\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 4.4579e-05 - val_loss: 0.0234\n",
      "Epoch 258/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - loss: 3.1416e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 4.9589e-05 - val_loss: 0.0236\n",
      "Epoch 259/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - loss: 2.5815e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 4.2081e-05 - val_loss: 0.0233\n",
      "Epoch 260/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - loss: 4.6087e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 4.5996e-05 - val_loss: 0.0238\n",
      "Epoch 261/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 5.8526e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 7.2550e-05 - val_loss: 0.0238\n",
      "Epoch 262/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 4.9498e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 6.8576e-05 - val_loss: 0.0233\n",
      "Epoch 263/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 6.2053e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 8.1427e-05 - val_loss: 0.0235\n",
      "Epoch 264/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - loss: 5.8475e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 1.0243e-04 - val_loss: 0.0232\n",
      "Epoch 265/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 28ms/step - loss: 1.0958e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 2.2416e-04 - val_loss: 0.0234\n",
      "Epoch 266/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 6.2994e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 1.4628e-04 - val_loss: 0.0241\n",
      "Epoch 267/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - loss: 0.0010\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 3.2112e-04 - val_loss: 0.0240\n",
      "Epoch 268/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 5.1307e-05\n",
      "\u001B[1m28/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37mâ”�\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.7527e-04 \n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 2.7851e-04 - val_loss: 0.0242\n",
      "Epoch 269/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m1s\u001B[0m 37ms/step - loss: 1.2511e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 2.7103e-04 - val_loss: 0.0233\n",
      "Epoch 270/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m1s\u001B[0m 39ms/step - loss: 7.3205e-05\n",
      "\u001B[1m23/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37mâ”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.3751e-04 \n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 1.4270e-04 - val_loss: 0.0236\n",
      "Epoch 271/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m4s\u001B[0m 152ms/step - loss: 2.5324e-04\n",
      "\u001B[1m17/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 2.3621e-04  \n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 2.1433e-04 - val_loss: 0.0238\n",
      "Epoch 272/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m1s\u001B[0m 41ms/step - loss: 1.1787e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 1.5231e-04 - val_loss: 0.0231\n",
      "Epoch 273/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m1s\u001B[0m 51ms/step - loss: 1.5572e-04\n",
      "\u001B[1m26/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37mâ”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.5053e-04 \n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 1.5032e-04 - val_loss: 0.0239\n",
      "Epoch 274/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m5s\u001B[0m 203ms/step - loss: 3.1866e-04\n",
      "\u001B[1m24/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37mâ”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 1.6418e-04  \n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 1.6128e-04 - val_loss: 0.0240\n",
      "Epoch 275/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m1s\u001B[0m 46ms/step - loss: 2.1209e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 1.5727e-04 - val_loss: 0.0238\n",
      "Epoch 276/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m1s\u001B[0m 65ms/step - loss: 1.1671e-04\n",
      "\u001B[1m22/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37mâ”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 1.0409e-04 \n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 1.0613e-04 - val_loss: 0.0232\n",
      "Epoch 277/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m1s\u001B[0m 55ms/step - loss: 8.2852e-05\n",
      "\u001B[1m27/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37mâ”�â”�\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 8.4888e-05 \n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 8.4722e-05 - val_loss: 0.0240\n",
      "Epoch 278/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m1s\u001B[0m 49ms/step - loss: 9.0837e-05\n",
      "\u001B[1m26/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37mâ”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 7.6101e-05 \n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 7.5360e-05 - val_loss: 0.0238\n",
      "Epoch 279/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m3s\u001B[0m 116ms/step - loss: 3.4066e-05\n",
      "\u001B[1m23/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37mâ”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 6.2851e-05  \n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 6.4689e-05 - val_loss: 0.0234\n",
      "Epoch 280/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m2s\u001B[0m 75ms/step - loss: 1.9474e-05\n",
      "\u001B[1m21/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37mâ”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 5.8063e-05 \n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 5.7686e-05 - val_loss: 0.0240\n",
      "Epoch 281/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m4s\u001B[0m 170ms/step - loss: 4.2759e-05\n",
      "\u001B[1m27/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37mâ”�â”�\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 4.5539e-05  \n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 4.5576e-05 - val_loss: 0.0234\n",
      "Epoch 282/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m1s\u001B[0m 38ms/step - loss: 1.4065e-05\n",
      "\u001B[1m26/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37mâ”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 3.3784e-05 \n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 3.5237e-05 - val_loss: 0.0237\n",
      "Epoch 283/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m3s\u001B[0m 134ms/step - loss: 5.3293e-05\n",
      "\u001B[1m14/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 3.8305e-05  \n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 4.0965e-05 - val_loss: 0.0238\n",
      "Epoch 284/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m1s\u001B[0m 49ms/step - loss: 6.0518e-05\n",
      "\u001B[1m28/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37mâ”�\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 4.5706e-05 \n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 4.5363e-05 - val_loss: 0.0236\n",
      "Epoch 285/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m1s\u001B[0m 58ms/step - loss: 1.9210e-05\n",
      "\u001B[1m21/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37mâ”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 3.4662e-05 \n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 3.6498e-05 - val_loss: 0.0239\n",
      "Epoch 286/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m1s\u001B[0m 66ms/step - loss: 1.5743e-05\n",
      "\u001B[1m22/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37mâ”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.6467e-05 \n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 2.8612e-05 - val_loss: 0.0235\n",
      "Epoch 287/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m1s\u001B[0m 41ms/step - loss: 1.8485e-05\n",
      "\u001B[1m22/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37mâ”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 2.7983e-05 \n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 2.9379e-05 - val_loss: 0.0238\n",
      "Epoch 288/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m1s\u001B[0m 50ms/step - loss: 1.2861e-05\n",
      "\u001B[1m22/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37mâ”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 4.5563e-05 \n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 4.5163e-05 - val_loss: 0.0236\n",
      "Epoch 289/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m1s\u001B[0m 37ms/step - loss: 2.0924e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 3.5899e-05 - val_loss: 0.0236\n",
      "Epoch 290/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 3.1185e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 3.3744e-05 - val_loss: 0.0235\n",
      "Epoch 291/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 2.2388e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 4.0308e-05 - val_loss: 0.0235\n",
      "Epoch 292/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - loss: 2.9197e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 5.2407e-05 - val_loss: 0.0238\n",
      "Epoch 293/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - loss: 9.0945e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 6.7489e-05 - val_loss: 0.0238\n",
      "Epoch 294/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m1s\u001B[0m 44ms/step - loss: 1.5691e-04\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 8.4575e-05 - val_loss: 0.0239\n",
      "Epoch 295/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - loss: 2.1061e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 6.6864e-05 - val_loss: 0.0236\n",
      "Epoch 296/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - loss: 4.2714e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 6.3236e-05 - val_loss: 0.0240\n",
      "Epoch 297/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 4.7260e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 6.6659e-05 - val_loss: 0.0236\n",
      "Epoch 298/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 6.2634e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 6.7213e-05 - val_loss: 0.0230\n",
      "Epoch 299/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - loss: 5.5272e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 7.4570e-05 - val_loss: 0.0231\n",
      "Epoch 300/300\n",
      "\n",
      "\u001B[1m 1/29\u001B[0m \u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - loss: 3.8175e-05\n",
      "\u001B[1m29/29\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 9.2409e-05 - val_loss: 0.0238\n",
      "\n",
      "\u001B[1m1/8\u001B[0m \u001B[32mâ”�â”�\u001B[0m\u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 0.0213\n",
      "\u001B[1m8/8\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0220 \n",
      "Test Loss (MSE): 0.023791512474417686\n",
      "Figure(640x480)\n",
      "\n",
      "\u001B[1m1/8\u001B[0m \u001B[32mâ”�â”�\u001B[0m\u001B[37mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m \u001B[1m0s\u001B[0m 111ms/step\n",
      "\u001B[1m8/8\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step \n",
      "\u001B[1m8/8\u001B[0m \u001B[32mâ”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�â”�\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step\n",
      "Figure(800x600)\n",
      "Figure(800x600)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-16 19:27:20.385220: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-16 19:27:21.931480: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "C:\\ProgramData\\miniconda3\\envs\\Data_Science_3_11\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-08-16 19:27:27.047704: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T17:31:44.916020Z",
     "start_time": "2024-08-16T17:31:44.903478Z"
    }
   },
   "cell_type": "code",
   "source": "display(Image(filename='plots/Learning Curves.png'))",
   "id": "4bc5ad9a3f24dfcf",
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 5. Exploratory Data Analysis (EDA)\n",
    "### 5.1. Initial Data Exploration:\n",
    "\n",
    "Visualize the distribution of text features (e.g., word frequencies).\n",
    "Analyze correlations between text features and target outcomes (disadvantage, segregation, failure).\n",
    "### 5.2. Data Visualization:\n",
    "\n",
    "Use graphs and charts to introduce the data. Visualize the distribution of key terms, document length, and any initial findings."
   ],
   "id": "197c0a9aedebfa68"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 6. Methodology\n",
    "### 6.1. Machine Learning Models:\n",
    "\n",
    "Start with simpler models (e.g., Logistic Regression) to predict the outcomes.\n",
    "Experiment with more complex models like Random Forests, Support Vector Machines, or Neural Networks.\n",
    "Consider using Ridge or Lasso regressions to handle high-dimensional text data.\n",
    "### 6.2. Model Evaluation:\n",
    "\n",
    "Use cross-validation to assess model performance.\n",
    "Evaluate models using metrics like accuracy, precision, recall, and F1 score.\n",
    "6.3. Causality Considerations:\n",
    "\n",
    "Discuss whether your models allow for causal inference or if they are purely correlational. Address any assumptions necessary for causal claims."
   ],
   "id": "d6fac52b2f533eed"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 7. Results\n",
    "### 7.1. Model Performance:\n",
    "\n",
    "Report the performance of different models. Include tables and graphs to compare results.\n",
    "Discuss how well your model fits the data and the significance of key predictors.\n",
    "### 7.2. Key Findings:\n",
    "\n",
    "Provide a clear summary of your findings. For example, identify which terms or phrases are most predictive of educational disadvantage."
   ],
   "id": "b231ad8d84cfabbf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 8. Conclusion\n",
    "### 8.1. Answer to Research Question:\n",
    "\n",
    "Provide a clear answer to your research question based on the analysis.\n",
    "Summarize the implications of your findings for educational policy or practice.\n",
    "### 8.2. Discussion:\n",
    "\n",
    "Discuss the limitations of your study, such as potential biases in the text data or limitations of the models used.\n",
    "Suggest areas for future research or improvements to the current analysis.\n",
    "## 9. Code Explanation and Documentation\n",
    "### 9.1. Code Comments and Documentation:\n",
    "\n",
    "Ensure that all code is well-commented and explained. Provide a detailed explanation of complex sections to ensure reproducibility.\n",
    "Include a README file in your repository to guide users on how to run the code and understand the analysis.\n",
    "### 9.2. References:\n",
    "\n",
    "Cite any external code or libraries you use. If you borrow code from online sources, provide proper attribution."
   ],
   "id": "78ff368e9d60c407"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4d7698e7bbc7a872"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
