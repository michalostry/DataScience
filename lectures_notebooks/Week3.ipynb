{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed7d6952-0d6c-40ea-ad95-a17962538b25",
   "metadata": {},
   "source": [
    "# week 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6b7f34c-8bc3-4045-9fcb-1a811280c580",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'country_codes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtheano\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcovid19pandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcod\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcountry_codes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m eurostat_dictionary\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01meurostat\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m filterwarnings\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'country_codes'"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "from scipy import optimize\n",
    "import pymc3 as pm\n",
    "import statsmodels.api as sm # check the error that cannot import name 'factorial' in from scipy.misc import factorial\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import altair as alt\n",
    "# from linearmodels.iv import IV2SLS\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow import keras\n",
    "import arviz as az\n",
    "\n",
    "import theano\n",
    "import covid19pandas as cod\n",
    "from country_codes import eurostat_dictionary\n",
    "import eurostat\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_moons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8f1013-f384-4131-94d9-ddda9a91a514",
   "metadata": {},
   "source": [
    "## ridge/lasso regressions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63b9e8d-8507-4793-a9e9-decb134ad4d3",
   "metadata": {},
   "source": [
    "* Lasso regressions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e33c2f-82cc-413c-ac50-6bc6df03535e",
   "metadata": {},
   "source": [
    "what OLS does is choose the slope of the paramteters to minimize the squared errors.\n",
    "The idea of lazzo regressions is that it changes the minimization problem , it's still (Y_i - beta_x^2) + a penalty term with lambda. On the penalty we want all our parameters to be 0. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71881ed2-b4c1-457b-a786-864124882e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_lasso (w,λ,X,y):\n",
    "    loss = np.sum((np.dot(X,w)-y)**2)/len(y) + λ*np.sum(np.abs(w))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41176992-b7ed-4b43-b4e4-dc05fbab9faa",
   "metadata": {},
   "source": [
    "we standarize the sum of squared errros by the number of observations we have (the lenght of y). If lambda is equal to zero we would have an ols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ed144f1-dae6-4037-a0bc-76581389642e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lasso_variables = []\n",
    "penalty = 1.0\n",
    "nobs = 100 #100 observations\n",
    "for i in range(100): #repeat experiment 100 times\n",
    "    X0=np.random.random((nobs,20)) #generated random random variables. IT's important to standarize the variables, rnaodm random generates numbers between 0 and 1. the matrix has 100 obs and 20 variables\n",
    "    X =np.c_[np.ones((nobs,1)),X0] #add the constant. create a vector that consists just of 1\n",
    "    beta = np.zeros(21) # the outcome should be that no variables are included in my model\n",
    "    e = np.random.random(nobs) # Generate a noise term. Just a vector of errors, not a matrix\n",
    "    y = np.dot(X,beta) + e\n",
    "    results= optimize.minimize(lambda w: loss_lasso(w,penalty,X,y),np.zeros(X.shape[1])) # initial guess is that they are zero\n",
    "    lasso_variables.append(np.sum(np.abs(results.x))) #if one of the coefficient is not zero, the sum would show it.\n",
    "plt.hist(lasso_variables,bins=7);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ed58b2-d2ee-4707-acac-8f9e81e1e197",
   "metadata": {},
   "source": [
    "All the coefficients are equal to 0. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3be2f3-0138-4360-af53-f58427290172",
   "metadata": {},
   "source": [
    "Program a lambda that is too high and shows that it's wrong what the lasso regressions does. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b53a97b2-39c6-4c6f-86b7-c819b8a69b3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lasso_variables = []\n",
    "penalty = 20.0\n",
    "nobs = 100 #100 observations\n",
    "for i in range(100): #repeat experiment 100 times\n",
    "    X0=np.random.random((nobs,20)) #generated random random variables. IT's important to standarize the variables, rnaodm random generates numbers between 0 and 1. the matrix has 100 obs and 20 variables\n",
    "    X =np.c_[np.ones((nobs,1)),X0] #add the constant. create a vector that consists just of 1\n",
    "    beta[1] = 1.0 # set the second beta to 1\n",
    "    e = np.random.random(nobs) # Generate a noise term. Just a vector of errors, not a matrix\n",
    "    y = np.dot(X,beta) + e\n",
    "    results= optimize.minimize(lambda w: loss_lasso(w,penalty,X,y),np.zeros(X.shape[1])) # initial guess is that they are zero\n",
    "    lasso_variables.append(np.sum(np.abs(results.x))) #if one of the coefficient is not zero, the sum would show it.\n",
    "plt.hist(lasso_variables,bins=7);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc39cd8c-ec03-4b78-a2fa-34718c6038b5",
   "metadata": {},
   "source": [
    "There are important causal relationship between the variabels that are droped out in the ridge or lasso regression. \n",
    "Lambda is a hyperparameter: it affects your model but is not estimate. You have to choose it wisely, you set it and it will have an effect on the outcome.\n",
    "We split up the data into a training and a test set. We estimate in the training set.\n",
    "A lasso regression never gives you the betas you are interested in. The lasso step only functions in selection your variables. You then use the variables in a normal regression without a penalty term. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91c5a627-c4df-4060-bdd8-f0be58180f39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [3, 4, 5]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.arange(6).reshape(2,3)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb54b895-f5f4-4d3e-bf22-3fe9b447df17",
   "metadata": {},
   "source": [
    "if I want to add a column 1,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4ae5629-793f-4a11-8ab5-446a7ccb9626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 1., 2.],\n",
       "       [1., 3., 4., 5.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.c_[np.ones(2),x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b9100ed-1251-488d-8094-6ff824c9c9a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b90378d-1edc-43ca-b226-8b693d9d2bfa",
   "metadata": {},
   "source": [
    "* Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9750d912-2865-4b29-a783-c5d37daedb17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def loss_ridge (w,λ,X,y):\n",
    "    loss = np.sum((np.dot(X,w)-y)**2)/len(y) + λ*np.sum(w**2)\n",
    "    return loss\n",
    "\n",
    "ridge_variables = []\n",
    "penalty = 1.0\n",
    "nobs = 100 #100 observations\n",
    "for i in range(100): #repeat experiment 100 times\n",
    "    X0=np.random.random((nobs,20)) #generated random random variables. IT's important to standarize the variables, rnaodm random generates numbers between 0 and 1. the matrix has 100 obs and 20 variables\n",
    "    X =np.c_[np.ones((nobs,1)),X0] #add the constant. create a vector that consists just of 1\n",
    "    beta = np.zeros(21) # the outcome should be that no variables are included in my model\n",
    "    e = np.random.random(nobs) # Generate a noise term. Just a vector of errors, not a matrix\n",
    "    y = np.dot(X,beta) + e\n",
    "    results= optimize.minimize(lambda w: loss_ridge(w,penalty,X,y),np.zeros(X.shape[1])) # initial guess is that they are zero\n",
    "    ridge_variables.append(np.sum(np.abs(results.x))) #if one of the coefficient is not zero, the sum would show it.\n",
    "plt.hist(ridge_variables,bins=7);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b62aae9-7098-4d24-94b4-39ad5553ac78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e4ceb49-8ae0-44a2-a6ee-fc3c0f225d67",
   "metadata": {},
   "source": [
    "## Causal reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc0468d-47de-43ac-8988-770d696e8675",
   "metadata": {},
   "outputs": [],
   "source": [
    "* Fork"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfe2ff8-0ee9-4638-b2f5-a0176625c5d0",
   "metadata": {},
   "source": [
    "We have x and y. They are both affected by z. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ef30ad9-cef6-481d-b0d0-2d57ed5e8502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.298771</td>\n",
       "      <td>-0.217575</td>\n",
       "      <td>-1.368554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.983712</td>\n",
       "      <td>1.735317</td>\n",
       "      <td>0.251566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.889506</td>\n",
       "      <td>-0.716911</td>\n",
       "      <td>-0.368550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.549896</td>\n",
       "      <td>0.348785</td>\n",
       "      <td>-0.597165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.319556</td>\n",
       "      <td>1.364140</td>\n",
       "      <td>-1.699088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x         y         z\n",
       "0 -2.298771 -0.217575 -1.368554\n",
       "1  0.983712  1.735317  0.251566\n",
       "2 -0.889506 -0.716911 -0.368550\n",
       "3 -0.549896  0.348785 -0.597165\n",
       "4 -3.319556  1.364140 -1.699088"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 100\n",
    "z = np.random.normal(0,1,size=n)\n",
    "x= 2*z + np.random.normal(0,1,size=n)\n",
    "y= -1*z + np.random.normal(0,1,size=n)\n",
    "data = pd.DataFrame({'x': x, 'y': y, 'z' : z})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3ea1006-db6b-40d7-bc70-f606aa4bf4bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.417</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.411</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   70.22</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 22 Feb 2024</td> <th>  Prob (F-statistic):</th> <td>3.91e-13</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:15:44</td>     <th>  Log-Likelihood:    </th> <td> -156.82</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   100</td>      <th>  AIC:               </th> <td>   317.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    98</td>      <th>  BIC:               </th> <td>   322.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    0.0140</td> <td>    0.117</td> <td>    0.120</td> <td> 0.905</td> <td>   -0.219</td> <td>    0.247</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x</th>         <td>   -0.3919</td> <td>    0.047</td> <td>   -8.379</td> <td> 0.000</td> <td>   -0.485</td> <td>   -0.299</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 9.856</td> <th>  Durbin-Watson:     </th> <td>   1.634</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.007</td> <th>  Jarque-Bera (JB):  </th> <td>   3.599</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.078</td> <th>  Prob(JB):          </th> <td>   0.165</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.084</td> <th>  Cond. No.          </th> <td>    2.51</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.417\n",
       "Model:                            OLS   Adj. R-squared:                  0.411\n",
       "Method:                 Least Squares   F-statistic:                     70.22\n",
       "Date:                Thu, 22 Feb 2024   Prob (F-statistic):           3.91e-13\n",
       "Time:                        11:15:44   Log-Likelihood:                -156.82\n",
       "No. Observations:                 100   AIC:                             317.6\n",
       "Df Residuals:                      98   BIC:                             322.9\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      0.0140      0.117      0.120      0.905      -0.219       0.247\n",
       "x             -0.3919      0.047     -8.379      0.000      -0.485      -0.299\n",
       "==============================================================================\n",
       "Omnibus:                        9.856   Durbin-Watson:                   1.634\n",
       "Prob(Omnibus):                  0.007   Jarque-Bera (JB):                3.599\n",
       "Skew:                           0.078   Prob(JB):                        0.165\n",
       "Kurtosis:                       2.084   Cond. No.                         2.51\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smf.ols('y ~ x', data=data).fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c21e288-7eac-4d0c-a30d-36b97a40f82c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.576</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.568</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   65.98</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 22 Feb 2024</td> <th>  Prob (F-statistic):</th> <td>8.14e-19</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:17:28</td>     <th>  Log-Likelihood:    </th> <td> -140.90</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   100</td>      <th>  AIC:               </th> <td>   287.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    97</td>      <th>  BIC:               </th> <td>   295.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   -0.0041</td> <td>    0.101</td> <td>   -0.041</td> <td> 0.968</td> <td>   -0.204</td> <td>    0.196</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x</th>         <td>    0.1102</td> <td>    0.092</td> <td>    1.193</td> <td> 0.236</td> <td>   -0.073</td> <td>    0.294</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>z</th>         <td>   -1.1998</td> <td>    0.199</td> <td>   -6.032</td> <td> 0.000</td> <td>   -1.595</td> <td>   -0.805</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>13.102</td> <th>  Durbin-Watson:     </th> <td>   1.714</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>   4.047</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.009</td> <th>  Prob(JB):          </th> <td>   0.132</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.015</td> <th>  Cond. No.          </th> <td>    5.87</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.576\n",
       "Model:                            OLS   Adj. R-squared:                  0.568\n",
       "Method:                 Least Squares   F-statistic:                     65.98\n",
       "Date:                Thu, 22 Feb 2024   Prob (F-statistic):           8.14e-19\n",
       "Time:                        11:17:28   Log-Likelihood:                -140.90\n",
       "No. Observations:                 100   AIC:                             287.8\n",
       "Df Residuals:                      97   BIC:                             295.6\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     -0.0041      0.101     -0.041      0.968      -0.204       0.196\n",
       "x              0.1102      0.092      1.193      0.236      -0.073       0.294\n",
       "z             -1.1998      0.199     -6.032      0.000      -1.595      -0.805\n",
       "==============================================================================\n",
       "Omnibus:                       13.102   Durbin-Watson:                   1.714\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):                4.047\n",
       "Skew:                           0.009   Prob(JB):                        0.132\n",
       "Kurtosis:                       2.015   Cond. No.                         5.87\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smf.ols('y ~ x + z', data=data).fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66291825-bf4f-4bbf-bb36-683eadd499d8",
   "metadata": {},
   "source": [
    "Now x is insignificant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db9a1a2-a4e9-412e-9ba0-a02040ebfdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "* pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cab84c6d-a304-406b-a23e-729221c1aedb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.528475</td>\n",
       "      <td>1.256494</td>\n",
       "      <td>0.137165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.180613</td>\n",
       "      <td>-5.336943</td>\n",
       "      <td>-2.265313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.771646</td>\n",
       "      <td>2.122228</td>\n",
       "      <td>1.006434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.373054</td>\n",
       "      <td>9.703692</td>\n",
       "      <td>2.842638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.923414</td>\n",
       "      <td>-22.091045</td>\n",
       "      <td>-6.692096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x          y         z\n",
       "0  0.528475   1.256494  0.137165\n",
       "1 -1.180613  -5.336943 -2.265313\n",
       "2  1.771646   2.122228  1.006434\n",
       "3  1.373054   9.703692  2.842638\n",
       "4 -1.923414 -22.091045 -6.692096"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 100\n",
    "x = np.random.normal(0,1,size=n) #x is now sort of the independent variable\n",
    "z= 2*x + np.random.normal(0,1,size=n)\n",
    "y= 3*z + np.random.normal(0,1,size=n)\n",
    "data = pd.DataFrame({'x': x, 'y': y, 'z' : z})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eb45ba23-4406-46d5-b890-30a29a5e0997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.979</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.978</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   2231.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 22 Feb 2024</td> <th>  Prob (F-statistic):</th> <td>8.01e-82</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:25:46</td>     <th>  Log-Likelihood:    </th> <td> -143.78</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   100</td>      <th>  AIC:               </th> <td>   293.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    97</td>      <th>  BIC:               </th> <td>   301.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    0.0732</td> <td>    0.107</td> <td>    0.682</td> <td> 0.497</td> <td>   -0.140</td> <td>    0.286</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x</th>         <td>   -0.0880</td> <td>    0.248</td> <td>   -0.355</td> <td> 0.724</td> <td>   -0.581</td> <td>    0.405</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>z</th>         <td>    3.0242</td> <td>    0.115</td> <td>   26.372</td> <td> 0.000</td> <td>    2.797</td> <td>    3.252</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.863</td> <th>  Durbin-Watson:     </th> <td>   1.940</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.394</td> <th>  Jarque-Bera (JB):  </th> <td>   1.850</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.264</td> <th>  Prob(JB):          </th> <td>   0.396</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.594</td> <th>  Cond. No.          </th> <td>    6.72</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.979\n",
       "Model:                            OLS   Adj. R-squared:                  0.978\n",
       "Method:                 Least Squares   F-statistic:                     2231.\n",
       "Date:                Thu, 22 Feb 2024   Prob (F-statistic):           8.01e-82\n",
       "Time:                        11:25:46   Log-Likelihood:                -143.78\n",
       "No. Observations:                 100   AIC:                             293.6\n",
       "Df Residuals:                      97   BIC:                             301.4\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      0.0732      0.107      0.682      0.497      -0.140       0.286\n",
       "x             -0.0880      0.248     -0.355      0.724      -0.581       0.405\n",
       "z              3.0242      0.115     26.372      0.000       2.797       3.252\n",
       "==============================================================================\n",
       "Omnibus:                        1.863   Durbin-Watson:                   1.940\n",
       "Prob(Omnibus):                  0.394   Jarque-Bera (JB):                1.850\n",
       "Skew:                           0.264   Prob(JB):                        0.396\n",
       "Kurtosis:                       2.594   Cond. No.                         6.72\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smf.ols('y ~ x + z', data=data).fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4ec04038-3b78-4ff0-a482-80e650d50864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.826</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.824</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   465.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 22 Feb 2024</td> <th>  Prob (F-statistic):</th> <td>5.15e-39</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:25:50</td>     <th>  Log-Likelihood:    </th> <td> -248.81</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   100</td>      <th>  AIC:               </th> <td>   501.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    98</td>      <th>  BIC:               </th> <td>   506.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   -0.6354</td> <td>    0.295</td> <td>   -2.151</td> <td> 0.034</td> <td>   -1.222</td> <td>   -0.049</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x</th>         <td>    5.9407</td> <td>    0.275</td> <td>   21.582</td> <td> 0.000</td> <td>    5.394</td> <td>    6.487</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 4.568</td> <th>  Durbin-Watson:     </th> <td>   2.257</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.102</td> <th>  Jarque-Bera (JB):  </th> <td>   3.891</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.440</td> <th>  Prob(JB):          </th> <td>   0.143</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.400</td> <th>  Cond. No.          </th> <td>    1.12</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.826\n",
       "Model:                            OLS   Adj. R-squared:                  0.824\n",
       "Method:                 Least Squares   F-statistic:                     465.8\n",
       "Date:                Thu, 22 Feb 2024   Prob (F-statistic):           5.15e-39\n",
       "Time:                        11:25:50   Log-Likelihood:                -248.81\n",
       "No. Observations:                 100   AIC:                             501.6\n",
       "Df Residuals:                      98   BIC:                             506.8\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     -0.6354      0.295     -2.151      0.034      -1.222      -0.049\n",
       "x              5.9407      0.275     21.582      0.000       5.394       6.487\n",
       "==============================================================================\n",
       "Omnibus:                        4.568   Durbin-Watson:                   2.257\n",
       "Prob(Omnibus):                  0.102   Jarque-Bera (JB):                3.891\n",
       "Skew:                          -0.440   Prob(JB):                        0.143\n",
       "Kurtosis:                       3.400   Cond. No.                         1.12\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smf.ols('y ~ x', data=data).fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ddcad9-37ca-4c44-9f07-da7a6c2c924f",
   "metadata": {},
   "outputs": [],
   "source": [
    "* collider"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
